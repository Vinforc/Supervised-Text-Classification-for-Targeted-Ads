{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b9f3b0-4e50-450d-989f-549842eddb9d",
   "metadata": {},
   "source": [
    "# **Contextual Advertising: Supervised Text Classification**\n",
    "\n",
    "Imagine you're a media buying company, Chrishare. They have a new client, Theragun.\n",
    "\n",
    "Theragun knows that consumers who value health and wellness are more likely to consider, and ultimately buy their product. So, they’d like to find health and wellness news around the web to advertise on. Their goal with their media campaign is to identify as many news articles that mention health and wellness as possible, but we will compare model results with a money-saving oriented goal as well.\n",
    "\n",
    "This is called contextual advertising: finding the URLs that match the context in which you’d like your ad to be show\n",
    "\n",
    "Our challenge now is to build a deep learning algorithm that predicts the probability that a news story is about health and wellness using k-train.\n",
    "\n",
    "\n",
    "# Dataset\n",
    "This dataset contains around 200k news headlines from the year 2012 to 2018 obtained from Huffpost. The model trained on this dataset could be used to identify tags for untracked news articles or to identify the type of language used in different news articles. Each news headline has a corresponding category (Health, Wellness, Entertainment, Politics, Sports, etc.).\n",
    "\n",
    "To prep for machine learning, we created classes \"Health\" and \"Not_Health\", where \"Health\" is entries containing the labeled categories HEALTH or WELLNESS, and \"Not_Health\" is all others. This came to a split of about 176k articles for not_health and about 24k for health. \n",
    "\n",
    "# Methodology\n",
    "To detect whether a news article belongs to the health/wellness category, a fine-tuned a transformer based text classifier using the ktrain wrapper over TensorFlow/Keras and HuggingFace transformers was implemented.\n",
    "\n",
    "For the input representation, each article was represented by concatrenating the headline and short_Description, separated by a [SEP] token. Including the short_description should provide richer context than using headlines alone. Before training, empty descriptions were replaced with empty strings, and duplicated/null rows were removed.\n",
    "\n",
    "### Model\n",
    "A BERT-based classifier provided by ktrain.text_classifer(\"bert\", ...) was used. BERT embeddings capture semantic meaning at the subword and sentence level, making them well-suited for contextual classification. The model was configured with a maximuim sequence of 96 tokens, which should balance the need to capture multi-sentence inputs while keeping computation manageable.\n",
    "\n",
    "### Class Imbalance\n",
    "The dataset is highly imbalanced at 176k to 24k entires, to counter this, class weights were implemented with sklearn.utils.class_weight. The minority was upweighted while the majority class was downweighted. During training, this re-scales the loss function so that misclassifying health articles is penalized more heavily, preventing the model from defaulting to predicting the majority class.\n",
    "\n",
    "### Training Strategy\n",
    "The one-cycle learning rate policy (fast convergence) with a maximum learning rate of 2e-5 for 3 epochs was utilized, a standard setup for fine-tuning BERT on medium sized text classification tasks. Batch size (# of samples that will be propagated through the network) was rasied to 92 and early stoppage was not implemented since the goal is only 3 epochs.\n",
    "\n",
    "### Evaluation\n",
    "The dataset was split 80/20 into training and validation sets. Model performance was evaluated on the validation set using ktrain's build in validate method, which reports precision, recall, F1-score, and support for each class. This provides insight into overall accuracy and the trade-off between catching more health articles (recall) vs minimizing false positives (precision). A confusion matrix was included to better track the false negatives (missed opportunities) and false positives (wasted ad-spend).\n",
    "\n",
    "### Threshold Tuning: Waste Less Ad-Dollars Vs Missed Opportunities\n",
    "\n",
    "Tuning the probability threshold can save ad-dollars by presenting ads to Health articles more confidently, but it will reduce the total number of real Health articles given. It can also be tuned to catch all the health articles, at the cost of ads wasted.\n",
    "\n",
    "The basic probability threshold is p(health) >= 0.5, so when there is a probability of 0.51 for p(health), then it will classify it as \"health\". \n",
    "\n",
    "This cutoff can be raised to get more confident classifications for the \"health\" class. This option can be useful for Theragun because ads will only be showed to high-confidence health pages. Maximizing precision can **save more ad dollars**.\n",
    "\n",
    "The threshold can also be lowered to increase recall, **maximizing the amount of positive ads** we send, at the expense of more misplaced ads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca4c5b-7cb6-45d1-8c67-950a59aeaa7a",
   "metadata": {},
   "source": [
    "# Results\n",
    "After training a supervised BERT-based classifier on the HuffPost headlines and short descriptions, the performance was evaluated on a held-out validation set (20% of ~200k total entries). The task was binary: Health (articles tagged WELLNESS or HEALTHY LIVING), and Not_Health (all other labeled categories)\n",
    "\n",
    "### Threshold\n",
    "\n",
    "The Validation set has about ~4900 Health and about 35100 Not_Health entries. \n",
    "\n",
    "The higher the threshold, the less coverage of the data we get (rejecting actual health articles due to low confidence). At threshold 97%, it reached about an 0.89 precision, keeping about 88.4% coverage across our data.\n",
    "\n",
    "While about 11.6% of total data was lost due to the threshold, this reduced the Health class by about 26% (rejecting ~26% of total health articles due to uncertainty), while keeping the number of false positives lower to maximize precision for less wasted ad dollars.\n",
    "\n",
    "To instead maximize the amount of total health articles classified without regard to wasted ads, the threshold can be lowered. Lowering the threshold to 0.05 only misses 224 health articles out of 4900, but we would be sending out 3365 bad ads to get 4775 good ones. Compared to the base threshold which sends out 1708 bad ads to get 4429 good ones, I do not think lowering the threshold is worth it.\n",
    "\n",
    "Raising the threshold to 0.97 means we are sending out 426 bad ads to get 3466 good ones. More information on the ad profitability are required to get the best threshold.\n",
    "\n",
    "### Classification Report & Confusion Matrix\n",
    "\n",
    "**Precision** measures how many of the pages flagged as “Health” were truly Health. A precision of 0.8896 means that 88.96% of the ad placements would be on wellness-related pages (low wasted spend).\n",
    "\n",
    "**Recall** measures how many of the actual Health pages were successfully caught. A recall of 0.9481 means detection of 94.81% of the available Health content (few missed opportunities). Rejected articles in the 0.97 and 0.05 thresholds are not factored into this recall calculation.\n",
    "\n",
    "**F1-score** is the harmonic mean of precision and recall, balancing the two into a single number.\n",
    "\n",
    "**Support** shows how many validation samples belonged to each class, which helps interpret the scores.\n",
    "\n",
    "**Macro Avg** shows how the model performs on each class equally, even if one class is more rare.\n",
    "\n",
    "**Weighted Avg** shows the average across all classes weighted by their support (number of samples)\n",
    "\n",
    "------------------------------------------------------------------------------------**Threshold: 0.05**----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "|Class | Precision | Recall | F1-Score | Support |\n",
    "|------|-----------|--------|----------|---------|\n",
    "|**Health**|0.58|0.95|0.72|4914|\n",
    "|**Not_Health**|0.99|0.90|0.95|35159|\n",
    "|**Accuracy**|||0.91|40073|\n",
    "|**Macro Avg**|0.79|0.9393|0.83|40073|\n",
    "|**Weighted Avg**|0.94|0.91|0.92|40073|\n",
    "\n",
    "\n",
    "| | Pred Health | Pred Not_Health |\n",
    "|---|---|----|\n",
    "|**True Health**|4690 |224 |\n",
    "|**True Not_Health**| 3365| 31794|\n",
    "\n",
    "\n",
    "**[4690, 224]** -> Health articles correctly identified vs misclassified\n",
    "\n",
    "**[3365, 31794]** -> Not_Health correctly identified vs misclassified\n",
    "\n",
    "*True positives (4690)*: Health articles correctly flagged\n",
    "\n",
    "*False neagtives (224)*: Health articles mistakenly flagged as Not_Health (lost opportunity) \n",
    "\n",
    "*False positives (3365)*: Not_Health predicted as Health (wasted ads)\n",
    "\n",
    "*True negatives (31794)*: Not-Health correctly predicted\n",
    "\n",
    "------------------------------------------------------------------------------------**Threshold: 0.50**----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "|Class | Precision | Recall | F1-Score | Support |\n",
    "|------|-----------|--------|----------|---------|\n",
    "|**Health**|0.72|0.90|0.80|4914|\n",
    "|**Not_Health**|0.99|0.95|0.97|35159|\n",
    "|**Accuracy**|||0.95|40073|\n",
    "|**Macro Avg**|0.85|0.93|0.89|40073|\n",
    "|**Weighted Avg**|0.95|0.95|0.95|40073|\n",
    "\n",
    "| | Pred Health | Pred Not_Health |\n",
    "|---|---|----|\n",
    "|**True Health**|4443 |471 |\n",
    "|**True Not_Health**| 1708| 33451|\n",
    "\n",
    "\n",
    "**[4443, 471]** -> Health articles correctly identified vs misclassified\n",
    "\n",
    "**[1708, 33451]** -> Not_Health correctly identified vs misclassified\n",
    "\n",
    "*True positives (4443)*: Health articles correctly flagged\n",
    "\n",
    "*False neagtives (471)*: Health articles mistakenly flagged as Not_Health (lost opportunity) \n",
    "\n",
    "*False positives (1708)*: Not_Health predicted as Health (wasted ads)\n",
    "\n",
    "*True negatives (33451)*: Not-Health correctly predicted\n",
    "\n",
    "------------------------------------------------------------------------------------**Threshold: 0.97**----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "|Class | Precision | Recall | F1-Score | Support |\n",
    "|------|-----------|--------|----------|---------|\n",
    "|**Health**|0.8896|0.9481|0.9179|3621|\n",
    "|**Not_Health**|0.9940|0.9866|0.9903|31801|\n",
    "|**Accuracy**|||0.9827|35422|\n",
    "|**Macro Avg**|0.9418|0.9673|0.9541|35422|\n",
    "|**Weighted Avg**|0.9834|0.9827|0.9829|35422|\n",
    "\n",
    "| | Pred Health | Pred Not_Health |\n",
    "|---|---|----|\n",
    "|**True Health**|3433 |188 |\n",
    "|**True Not_Health**| 426| 31375|\n",
    "\n",
    "\n",
    "**[3433, 188]** -> Health articles correctly identified vs misclassified\n",
    "\n",
    "**[426, 31375]** -> Not_Health correctly misclassified vs identified\n",
    "\n",
    "*True positives (3433)*: Health articles correctly flagged\n",
    "\n",
    "*False neagtives (188)*: Health articles mistakenly flagged as Not_Health (lost opportunity) \n",
    "\n",
    "*False positives (426)*: Not_Health predicted as Health (wasted ads)\n",
    "\n",
    "*True negatives (31375)*: Not-Health correctly predicted\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "At the 0.97 threshold, the model prioritized precision (minimizing wasted ads) while maintaining strong recall (capturing the majority of wellness content), but rejects about 26% of total health ads in our validation data due to poor confidence. This trade-off may be well-aligned with Theragun's campaign goals: ensuring their ads appear in high-quality health contexts without overspending on irrelevant inventory.\n",
    "\n",
    "\n",
    "At 0.50 threshold, we identify an extra ~1000 total true (about 30% increase) health articles at the cost of more false positives. There are 4x more false positives which equates to about ~1300 more wasted ads compared to the 0.97 threshold, which could be costly. \n",
    "\n",
    "At the 0.05 threshold, only about an extra ~300 health articles are identified at the cost of an 3365 extra bad health articles. More information on the profitability of the ads are required to know which approach is best.\n",
    "\n",
    "### Future Research & Improvements\n",
    "\n",
    "Future research could look into the unconfident articles specifically, get to the root cause of why it is not confident, and adjust parameters from there. \n",
    "\n",
    "If there is a probability that misclassified ads are still converted into a sale, then misclassifying a proportion of ads may be more tolerable. After running the campaign, analyze the misclassified ads to check if any converted. From there, the company can possibly expand the target domain to include other categories.\n",
    "\n",
    "Possible improvements to increase recall and maximize the number of good health ads sent: increase weights to the Health class, undersample not_health or oversample health, increasing the token length to 128, try a different model backbone (RoBERTa-base or DistilBERT), or supplement the current model with a new model (TF-IDF, LR/SVM) that flags extra health candidates and union the positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "05db316f-beea-45a0-ab54-ac3f148626a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200853, 6)\n",
      "        category                                           headline  \\\n",
      "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
      "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
      "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
      "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
      "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
      "\n",
      "           authors                                               link  \\\n",
      "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
      "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
      "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
      "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
      "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
      "\n",
      "                                   short_description        date  \n",
      "0  She left her husband. He killed their children...  2018-05-26  \n",
      "1                           Of course it has a song.  2018-05-26  \n",
      "2  The actor and his longtime girlfriend Anna Ebe...  2018-05-26  \n",
      "3  The actor gives Dems an ass-kicking for not fi...  2018-05-26  \n",
      "4  The \"Dietland\" actress said using the bags is ...  2018-05-26  \n",
      "category\n",
      "POLITICS          32739\n",
      "WELLNESS          17827\n",
      "ENTERTAINMENT     16058\n",
      "TRAVEL             9887\n",
      "STYLE & BEAUTY     9649\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = \"news_category_trainingdata.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Each top-level key is a column, each value is a dict of {row_index: value}\n",
    "# Rebuild rows by zipping values across columns\n",
    "df = pd.DataFrame({col: pd.Series(vals) for col, vals in data.items()})\n",
    "\n",
    "# Reset index and drop NAs\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.dropna(subset=[\"category\", \"headline\"])\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df[\"category\"].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88206e3f-2c50-445a-a9d5-01e2dc11bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_str\n",
      "Not_Health    176332\n",
      "Health         24521\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add Labels for Health/Wellness\n",
    "health_cats = {\"WELLNESS\", \"HEALTHY LIVING\"}\n",
    "df[\"label_str\"] = df[\"category\"].apply(lambda x: \"Health\" if x in health_cats else \"Not_Health\")\n",
    "print(df[\"label_str\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13aecc9a-5902-4508-b35c-dbcc63584bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n",
      "Class weights: {0: 4.089916309450908, 1: 0.5696395064536305}\n",
      "Is Multi-Label? False\n",
      "maxlen is 96\n",
      "done.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/3\n",
      "5010/5010 [==============================] - 31246s 6s/step - loss: 0.2216 - accuracy: 0.9074 - val_loss: 0.2146 - val_accuracy: 0.9109\n",
      "Epoch 2/3\n",
      "5010/5010 [==============================] - 28989s 6s/step - loss: 0.1566 - accuracy: 0.9315 - val_loss: 0.1772 - val_accuracy: 0.9300\n",
      "Epoch 3/3\n",
      "5010/5010 [==============================] - 28980s 6s/step - loss: 0.0803 - accuracy: 0.9644 - val_loss: 0.1639 - val_accuracy: 0.9456\n",
      "ktrain class order: ['Health', 'Not_Health']\n",
      "1253/1253 [==============================] - 2123s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health       0.72      0.90      0.80      4914\n",
      "  Not_Health       0.99      0.95      0.97     35159\n",
      "\n",
      "    accuracy                           0.95     40073\n",
      "   macro avg       0.85      0.93      0.89     40073\n",
      "weighted avg       0.95      0.95      0.95     40073\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4443,   471],\n",
       "       [ 1708, 33451]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Build a stronger input field: headline + short_description\n",
    "df[\"short_description\"] = df[\"short_description\"].fillna(\"\")\n",
    "df[\"text\"] = (df[\"headline\"].astype(str).str.strip()\n",
    "              + \" [SEP] \"\n",
    "              + df[\"short_description\"].astype(str).str.strip())\n",
    "# Clean/dedup\n",
    "df = df.dropna(subset=[\"text\", \"label_str\"])\n",
    "df = df[df[\"text\"].str.len() > 0].drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Class names must match labels\n",
    "class_names = [\"Health\", \"Not_Health\"]\n",
    "\n",
    "# Split into train/val and preprocess with BERT (96 tokens)\n",
    "(x_train, y_train), (x_val, y_val), preproc = text.texts_from_array(\n",
    "    x_train = df[\"text\"].values,\n",
    "    y_train = df[\"label_str\"].values,\n",
    "    class_names = class_names,\n",
    "    val_pct = 0.2,\n",
    "    maxlen = 96,\n",
    "    preprocess_mode = \"bert\",\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Class-weighted loss to counter imbalance \n",
    "classes = np.arange(len(preproc.get_classes()))     # e.g., [0,1]\n",
    "y_train_ids = y_train.argmax(1) if getattr(y_train, \"ndim\", 1) == 2 else y_train\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train_ids)\n",
    "class_weight = {int(i): float(w) for i, w in zip(classes, cw)}\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "# Build classifier\n",
    "model = text.text_classifier(\"bert\", (x_train, y_train), preproc=preproc)\n",
    "\n",
    "# Wrap in learner\n",
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_val, y_val), batch_size=96)\n",
    "\n",
    "# Train (3 epochs usually enough for BERT on this dataset) (wont need early stoppage with only 3 epoch)\n",
    "learner.fit_onecycle(2e-5, 3, class_weight=class_weight)\n",
    "\n",
    "# Evaluate\n",
    "actual_classes = preproc.get_classes()\n",
    "print(\"ktrain class order:\", actual_classes)\n",
    "learner.validate(val_data=(x_val, y_val), class_names=actual_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9fc17fa-0817-41d8-ac3e-dce794b52f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.7223    0.9042    0.8031      4914\n",
      "  Not_Health     0.9861    0.9514    0.9685     35159\n",
      "\n",
      "    accuracy                         0.9456     40073\n",
      "   macro avg     0.8542    0.9278    0.8858     40073\n",
      "weighted avg     0.9538    0.9456    0.9482     40073\n",
      "\n",
      "[[ 4443   471]\n",
      " [ 1708 33451]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Use the tensors returned by texts_from_array\n",
    "x_inputs = x_val                             # tuple/list of arrays for transformers\n",
    "y_true = y_val.argmax(1) if y_val.ndim == 2 else y_val\n",
    "\n",
    "# Model probabilities -> class ids\n",
    "probs  = learner.model.predict(x_inputs, verbose=0)\n",
    "y_pred = probs.argmax(1)\n",
    "\n",
    "# Class names from the preprocessor (source of truth)\n",
    "names = preproc.get_classes()\n",
    "print(classification_report(y_true, y_pred, target_names=names, digits=4))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "296dfa86-bc25-4e93-805a-cb5255d67b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.75\n",
      "Kept 38738/40073 samples (96.7% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.7762    0.9253    0.8442      4603\n",
      "  Not_Health     0.9897    0.9640    0.9767     34135\n",
      "\n",
      "    accuracy                         0.9594     38738\n",
      "   macro avg     0.8829    0.9446    0.9104     38738\n",
      "weighted avg     0.9643    0.9594    0.9609     38738\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4259   344]\n",
      " [ 1228 32907]]\n"
     ]
    }
   ],
   "source": [
    "# setting a threshold of 0.75 for both classes, rejecting the rest, rechecking validation\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Evaluate with a reject option using precomputed class probabilities.\n",
    "    probs: np.ndarray, shape (N, 2)  -> model probabilities per class\n",
    "    y_val: one-hot or int labels\n",
    "    classes: list like ['Health', 'Not_Health']\n",
    "    \"\"\"\n",
    "    # true labels as ints\n",
    "    y_true = y_val.argmax(1) if getattr(y_val, \"ndim\", 1) == 2 else y_val\n",
    "\n",
    "    # class indices\n",
    "    h_idx = classes.index('Health')\n",
    "    nh_idx = classes.index('Not_Health')\n",
    "\n",
    "    p_health = probs[:, h_idx]\n",
    "    p_not    = probs[:, nh_idx]\n",
    "\n",
    "    # apply thresholds with reject (to not reduce recall)\n",
    "    y_pred = np.full_like(y_true, fill_value=-1)\n",
    "    y_pred[p_health >= threshold] = h_idx\n",
    "    y_pred[(p_not >= threshold) & (y_pred == -1)] = nh_idx\n",
    "\n",
    "    # keep confident only\n",
    "    mask = (y_pred != -1)\n",
    "    kept_true, kept_pred = y_true[mask], y_pred[mask]\n",
    "\n",
    "    print(f\"Threshold = {threshold}\")\n",
    "    print(f\"Kept {mask.sum()}/{len(y_pred)} samples ({100*mask.mean():.1f}% coverage)\\n\")\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        print(\"No samples met the threshold.\")\n",
    "        return\n",
    "\n",
    "    print(\"Classification Report (confident samples only):\")\n",
    "    print(classification_report(kept_true, kept_pred, target_names=classes, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(kept_true, kept_pred))\n",
    "\n",
    "# get probs from the model (since x_val is tokenized tensors) \n",
    "probs = learner.model.predict(x_val, verbose=0)   # shape (N, 2)\n",
    "classes = preproc.get_classes()                   # ['Health','Not_Health']\n",
    "\n",
    "# run evaluation with reject threshold=0.75\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0e343914-8857-4c78-805f-ab85c4afa426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       run evaluation with reject threshold=0.80\n",
      "Threshold = 0.8\n",
      "Kept 38374/40073 samples (95.8% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.7909    0.9297    0.8547      4509\n",
      "  Not_Health     0.9904    0.9673    0.9787     33865\n",
      "\n",
      "    accuracy                         0.9629     38374\n",
      "   macro avg     0.8907    0.9485    0.9167     38374\n",
      "weighted avg     0.9670    0.9629    0.9641     38374\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4192   317]\n",
      " [ 1108 32757]]\n",
      "                       run evaluation with reject threshold=0.85\n",
      "Threshold = 0.85\n",
      "Kept 37948/40073 samples (94.7% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.8074    0.9339    0.8661      4400\n",
      "  Not_Health     0.9911    0.9708    0.9809     33548\n",
      "\n",
      "    accuracy                         0.9665     37948\n",
      "   macro avg     0.8993    0.9523    0.9235     37948\n",
      "weighted avg     0.9698    0.9665    0.9675     37948\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4109   291]\n",
      " [  980 32568]]\n",
      "                       run evaluation with reject threshold=0.90\n",
      "Threshold = 0.9\n",
      "Kept 37342/40073 samples (93.2% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.8289    0.9387    0.8804      4228\n",
      "  Not_Health     0.9920    0.9753    0.9836     33114\n",
      "\n",
      "    accuracy                         0.9711     37342\n",
      "   macro avg     0.9105    0.9570    0.9320     37342\n",
      "weighted avg     0.9736    0.9711    0.9719     37342\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3969   259]\n",
      " [  819 32295]]\n",
      "                       run evaluation with reject threshold=0.95\n",
      "Threshold = 0.95\n",
      "Kept 36292/40073 samples (90.6% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.8641    0.9428    0.9017      3917\n",
      "  Not_Health     0.9930    0.9821    0.9875     32375\n",
      "\n",
      "    accuracy                         0.9778     36292\n",
      "   macro avg     0.9285    0.9624    0.9446     36292\n",
      "weighted avg     0.9791    0.9778    0.9782     36292\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3693   224]\n",
      " [  581 31794]]\n",
      "                       run evaluation with reject threshold 0.97\n",
      "Threshold = 0.97\n",
      "Kept 35422/40073 samples (88.4% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.8896    0.9481    0.9179      3621\n",
      "  Not_Health     0.9940    0.9866    0.9903     31801\n",
      "\n",
      "    accuracy                         0.9827     35422\n",
      "   macro avg     0.9418    0.9673    0.9541     35422\n",
      "weighted avg     0.9834    0.9827    0.9829     35422\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3433   188]\n",
      " [  426 31375]]\n",
      "                       run evaluation with reject threshold 0.98\n",
      "Threshold = 0.98\n",
      "Kept 34607/40073 samples (86.4% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.9096    0.9507    0.9297      3324\n",
      "  Not_Health     0.9947    0.9900    0.9923     31283\n",
      "\n",
      "    accuracy                         0.9862     34607\n",
      "   macro avg     0.9522    0.9703    0.9610     34607\n",
      "weighted avg     0.9866    0.9862    0.9863     34607\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3160   164]\n",
      " [  314 30969]]\n",
      "                       run evaluation with reject threshold 0.99\n",
      "Threshold = 0.99\n",
      "Kept 33082/40073 samples (82.6% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.9435    0.9487    0.9461      2709\n",
      "  Not_Health     0.9954    0.9949    0.9952     30373\n",
      "\n",
      "    accuracy                         0.9911     33082\n",
      "   macro avg     0.9694    0.9718    0.9706     33082\n",
      "weighted avg     0.9912    0.9911    0.9912     33082\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2570   139]\n",
      " [  154 30219]]\n"
     ]
    }
   ],
   "source": [
    "print(\"                       run evaluation with reject threshold=0.80\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.80)\n",
    "print(\"                       run evaluation with reject threshold=0.85\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.85)\n",
    "print(\"                       run evaluation with reject threshold=0.90\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.90)\n",
    "print(\"                       run evaluation with reject threshold=0.95\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.95)\n",
    "\n",
    "print(\"                       run evaluation with reject threshold 0.97\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.97)\n",
    "print(\"                       run evaluation with reject threshold 0.98\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.98)\n",
    "print(\"                       run evaluation with reject threshold 0.99\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4a351cc3-344d-4f07-8e7e-b91ed9e86113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       run evaluation with reject threshold 0.05\n",
      "Threshold = 0.05\n",
      "Kept 40073/40073 samples (100.0% coverage)\n",
      "\n",
      "Classification Report (confident samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.5822    0.9544    0.7233      4914\n",
      "  Not_Health     0.9930    0.9043    0.9466     35159\n",
      "\n",
      "    accuracy                         0.9104     40073\n",
      "   macro avg     0.7876    0.9294    0.8349     40073\n",
      "weighted avg     0.9426    0.9104    0.9192     40073\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4690   224]\n",
      " [ 3365 31794]]\n"
     ]
    }
   ],
   "source": [
    "print(\"                       run evaluation with reject threshold 0.05\")\n",
    "evaluate_with_reject_from_probs(probs, y_val, classes, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0646294a-92e8-45e0-8fc7-44d654efdd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugh Grant Marries For The First Time At Age 57\n",
      "The actor and his longtime girlfriend Anna Eberstein tied the knot in a civil ceremony.\n"
     ]
    }
   ],
   "source": [
    "first_description = df['short_description'].iloc[2]\n",
    "first_headline = df['headline'].iloc[2]\n",
    "print(first_headline)\n",
    "print(first_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "10bc8efe-c045-4926-8495-f5c5f0c0637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, headline, authors, link, short_description, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health = df[df['category'] == \"HEALTH\"]\n",
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9e5ff-9c64-40e4-8ad9-b0264f7105b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers_env)",
   "language": "python",
   "name": "transformers_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
